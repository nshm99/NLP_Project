# -*- coding: utf-8 -*-
"""Copy of Sentencepiece python module example

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZZ9vJ_nIQkgjW776lnPvwVfRHuOKvbz8

# Sentencepiece python module


This notebook describes comprehensive examples of sentencepiece Python module. 
Since Python module calls C++ API through SWIG,  this document is also useful for developing C++ client.

## Install and data preparation

We use the small training data (botchan.txt) in this example. 
([Botchan](https://en.wikipedia.org/wiki/Botchan) is a novel written by Natsume S≈çseki in 1906.  The sample is English-translated one.)
"""

"""## Basic  end-to-end example


"""

import numpy as np
import pandas as pd
import sentencepiece as spm
import dataframe_image as dfi

combined_data = pd.read_csv('../../data/process/combined_data.csv')
data = combined_data['text']

splitted = np.array_split(data,5)

def build_text_files(texts, dest_path):
    with open(dest_path, 'w',encoding='utf-8') as f:
        f.write('\n'.join(texts))

# print(splitted[0])

vocab=[10,30,100,1000,4054]
unk_counts=[]
for i in range(5):
  splitted_copy = splitted.copy()
  splitted_data_test = splitted_copy.pop(i)
  splitted_data = np.concatenate(splitted_copy).tolist()
  
  build_text_files(splitted_data, 'train.txt')
  s = vocab[i]
  spm.SentencePieceTrainer.train(f'--input=train.txt --model_prefix=../../models/m_{s} --vocab_size={s} --model_type=word')

  sp = spm.SentencePieceProcessor()
  sp.load(f'../../models/m_{s}.model')

  total = 0
  unk_count = 0
  # print(splitted_data_test)
  for sentence in splitted_data_test:
    sp_ids = sp.encode_as_ids(sentence)
    sp_pices = sp.encode_as_pieces(sentence)
    total += len(sp_ids)
    unk_count += sp_ids.count(0)
    unk_count -= (sp_pices.count('<s>')+sp_pices.count('</s>'))

  unk_counts.append(unk_count/total)

print(unk_counts)

df = pd.DataFrame( {"count": unk_counts})
df.to_csv('../../reports/tokenization_counts.csv', index = False)
dfi.export(df, '../../reports/dataframe.png')

