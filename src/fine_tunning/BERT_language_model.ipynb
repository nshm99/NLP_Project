{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtzXM2PS1EcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d29814-b390-4f03-e2d3-e687cf949e03"
      },
      "source": [
        "!pip install transformers==4.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 27.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 33.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 27.9MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 28.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 29.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 31.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 26.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 27.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 28.1MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 28.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 28.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 28.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143kB 28.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 28.1MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 28.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174kB 28.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184kB 28.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194kB 28.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 204kB 28.1MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 28.1MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 28.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 235kB 28.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 245kB 28.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256kB 28.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 266kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 296kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 307kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 327kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 337kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 358kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 368kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 389kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 399kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 409kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 419kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 430kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 440kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 450kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 460kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 471kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 481kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 491kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 512kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 522kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 532kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 542kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 563kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 573kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 583kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 593kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 604kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 614kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 624kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 634kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 645kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 655kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 675kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 686kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 696kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 706kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 716kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 727kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 737kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 747kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 757kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 768kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 788kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 798kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 808kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 819kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 829kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 839kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 849kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 860kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 870kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 880kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 890kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 901kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 911kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 921kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 931kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 942kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 952kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 962kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 972kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 983kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 993kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.0MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7MB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.5.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 48.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.2) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcnKzcynKkmg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "# from transformers import AutoModel, BertTokenizerFast\n",
        "# from transformers import BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weAo8Y4A4Lhx"
      },
      "source": [
        "def build_text_files(texts, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    for text in texts:\n",
        "        data += text + \"  \"\n",
        "    f.write(data)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIgjAkO5AzF"
      },
      "source": [
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "     \n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)   \n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "wbDTo6uoK0n5",
        "outputId": "65917ca1-e470-4d7c-db1f-7b9d573fe1cc"
      },
      "source": [
        "combined_data = pd.read_csv('combined_data.csv')\n",
        "# combined_data = pd.read_csv('combined_data_sentence_broken.csv')\n",
        "combined_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>subject</th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://forge.medium.com/you-dont-need-more-mo...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>0.txt</td>\n",
              "      <td>358</td>\n",
              "      <td>0</td>\n",
              "      <td>'one greatest talents has always been coming w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://medium.com/swlh/theres-no-such-thing-a...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>1.txt</td>\n",
              "      <td>1243</td>\n",
              "      <td>0</td>\n",
              "      <td>highly motivated.', don’t have amazing willpow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://medium.com/the-mission/the-most-motiva...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>2.txt</td>\n",
              "      <td>639</td>\n",
              "      <td>0</td>\n",
              "      <td>motivational statement comes down three words:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://medium.com/swlh/how-to-make-yourself-w...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>3.txt</td>\n",
              "      <td>884</td>\n",
              "      <td>0</td>\n",
              "      <td>break the chain.”', 'these four simple words h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://betterhumans.pub/how-to-do-a-life-chan...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>4.txt</td>\n",
              "      <td>980</td>\n",
              "      <td>0</td>\n",
              "      <td>'when most people think accountability partner...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  ...                                               text\n",
              "0  https://forge.medium.com/you-dont-need-more-mo...  ...  'one greatest talents has always been coming w...\n",
              "1  https://medium.com/swlh/theres-no-such-thing-a...  ...  highly motivated.', don’t have amazing willpow...\n",
              "2  https://medium.com/the-mission/the-most-motiva...  ...  motivational statement comes down three words:...\n",
              "3  https://medium.com/swlh/how-to-make-yourself-w...  ...  break the chain.”', 'these four simple words h...\n",
              "4  https://betterhumans.pub/how-to-do-a-life-chan...  ...  'when most people think accountability partner...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQ_MvuE1kPI"
      },
      "source": [
        "Motivational\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kUL4SoH4oBN"
      },
      "source": [
        "combined_data = combined_data[(combined_data['class']==0)]\n",
        "\n",
        "train_text, valid_text, train_labels, val_labels = train_test_split(combined_data['text'].tolist(), combined_data['class'].tolist(), \n",
        "                                                                    test_size=0.15)\n",
        "train_path = 'train_dataset.txt'\n",
        "test_path = 'test_dataset.txt'\n",
        "\n",
        "build_text_files(train_text, train_path)\n",
        "build_text_files(valid_text, test_path)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQWiehwrNnIY"
      },
      "source": [
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCpFOcOZK5Cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc68dac-a205-4186-adf1-1399088bb5a7"
      },
      "source": [
        "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhHBazJHZ0i6",
        "outputId": "02677efc-fe0b-4049-e7e5-60528cf7267c"
      },
      "source": [
        "model = AutoModelWithLMHead.from_pretrained(\"distilgpt2\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:925: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wJab2UvTZ5T5",
        "outputId": "518c1d82-f610-429a-f369-a829c5c39752"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./motivational.bert_lm',          \n",
        "    overwrite_output_dir=True, \n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32, \n",
        "    per_device_eval_batch_size=64,  \n",
        "    eval_steps = 400, \n",
        "    save_steps=800, \n",
        "    warmup_steps=500,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,  \n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,   \n",
        "    eval_dataset=test_dataset,     \n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 00:31, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=48, training_loss=5.025032043457031, metrics={'train_runtime': 32.7384, 'train_samples_per_second': 1.466, 'total_flos': 93230928101376, 'epoch': 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "xOq09VG-eVDu",
        "outputId": "21ccf4d1-8065-4b17-9fa7-33e297f8453c"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_loss': 4.8174614906311035,\n",
              " 'eval_runtime': 0.6301,\n",
              " 'eval_samples_per_second': 122.201}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdp2cMQF42AB"
      },
      "source": [
        "# model.save_pretrained(\"/content/gdrive/MyDrive/models/bert_classification_lm\")\n",
        "trainer.save_model()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFfsj7i5nia"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipline = pipeline('text-generation',model='./motivational.bert_lm', tokenizer='distilgpt2',config={'max_length':800})\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "iJk9X-Cc6nY2",
        "outputId": "8f588624-5d8b-46b9-ac1b-df619aa40080"
      },
      "source": [
        "pipline('being productive is to')[0]['generated_text']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'being productive is to use tools that may help,” in this situation, it is likely that you have developed tools that may help the user use tools that may help improve productivity using tools that may help productivity in your own life.\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3GoISxDaVa0",
        "outputId": "d94344bf-f970-4544-e583-84f5823b0182"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Rz0E513jsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee760797-91aa-4928-f412-5782928eeffa"
      },
      "source": [
        "!zip \"/content/motivational.bert_lm.zip\" \"/content/motivational.bert_lm\"\n",
        "!cp \"/content/motivational.bert_lm.zip\" \"/content/drive/MyDrive\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/motivational.bert_lm/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiArGGYH2koe"
      },
      "source": [
        "non Motivational"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhXmREeI4BVW",
        "outputId": "15e6723e-9fc3-405b-81b5-2575f088a610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "combined_data = pd.read_csv('combined_data.csv')\n",
        "combined_data.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>subject</th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://forge.medium.com/you-dont-need-more-mo...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>0.txt</td>\n",
              "      <td>358</td>\n",
              "      <td>0</td>\n",
              "      <td>'one greatest talents has always been coming w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://medium.com/swlh/theres-no-such-thing-a...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>1.txt</td>\n",
              "      <td>1243</td>\n",
              "      <td>0</td>\n",
              "      <td>highly motivated.', don’t have amazing willpow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://medium.com/the-mission/the-most-motiva...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>2.txt</td>\n",
              "      <td>639</td>\n",
              "      <td>0</td>\n",
              "      <td>motivational statement comes down three words:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://medium.com/swlh/how-to-make-yourself-w...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>3.txt</td>\n",
              "      <td>884</td>\n",
              "      <td>0</td>\n",
              "      <td>break the chain.”', 'these four simple words h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://betterhumans.pub/how-to-do-a-life-chan...</td>\n",
              "      <td>motivation</td>\n",
              "      <td>4.txt</td>\n",
              "      <td>980</td>\n",
              "      <td>0</td>\n",
              "      <td>'when most people think accountability partner...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  ...                                               text\n",
              "0  https://forge.medium.com/you-dont-need-more-mo...  ...  'one greatest talents has always been coming w...\n",
              "1  https://medium.com/swlh/theres-no-such-thing-a...  ...  highly motivated.', don’t have amazing willpow...\n",
              "2  https://medium.com/the-mission/the-most-motiva...  ...  motivational statement comes down three words:...\n",
              "3  https://medium.com/swlh/how-to-make-yourself-w...  ...  break the chain.”', 'these four simple words h...\n",
              "4  https://betterhumans.pub/how-to-do-a-life-chan...  ...  'when most people think accountability partner...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVXVu17i2mGW"
      },
      "source": [
        "combined_data = combined_data[(combined_data['class'] == 1)]\n",
        "\n",
        "train_text, valid_text, train_labels, val_labels = train_test_split(combined_data['text'].tolist(), combined_data['class'].tolist(), \n",
        "                                                                    test_size=0.15)\n",
        "train_path = 'train_dataset.txt'\n",
        "test_path = 'test_dataset.txt'\n",
        "\n",
        "build_text_files(train_text, train_path)\n",
        "build_text_files(valid_text, test_path)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd6NMsab3kX4",
        "outputId": "56e46f91-8851-48fe-d6bf-647bd648a890"
      },
      "source": [
        "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "68Fhk2wG3kX6",
        "outputId": "81800a92-9016-4639-e99e-4af9b260acf3"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./nonMotivational.bert_lm',          \n",
        "    overwrite_output_dir=True, \n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32, \n",
        "    per_device_eval_batch_size=64,  \n",
        "    eval_steps = 400, \n",
        "    save_steps=800, \n",
        "    warmup_steps=500,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                    \n",
        "    args=training_args,             \n",
        "    train_dataset=train_dataset,    \n",
        "    eval_dataset=test_dataset,      \n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 00:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=48, training_loss=4.80613644917806, metrics={'train_runtime': 33.2198, 'train_samples_per_second': 1.445, 'total_flos': 93230928101376, 'epoch': 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "pPEk0KPj3kX7",
        "outputId": "d37329cc-c98f-4039-c02b-12294be2a9e6"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_loss': 4.683315753936768,\n",
              " 'eval_runtime': 0.6317,\n",
              " 'eval_samples_per_second': 121.902}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIwgowwW3kX7"
      },
      "source": [
        "# model.save_pretrained(\"/content/gdrive/MyDrive/models/bert_classification_lm\")\n",
        "trainer.save_model()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQAYKxZC3kX7"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipline = pipeline('text-generation',model='./nonMotivational.bert_lm', tokenizer='distilgpt2',config={'max_length':800})\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bRX9TQTs3kX8",
        "outputId": "44ab5ef3-8e4b-423d-eb72-84cd5d5e61ce"
      },
      "source": [
        "pipline('politic is')[0]['generated_text']"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'politic is about social justice, but does work well for social justice as far as society is concerned. This has taken my life, I have had a difficult time doing so much as I’m ashamed and even angry,’ and I'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1jhj69d3kX8",
        "outputId": "619409a0-a148-471a-f420-91c9ecd31093"
      },
      "source": [
        "!zip \"/content/nonMotivational.bert_lm.zip\" \"/content/nonMotivational.bert_lm\"\n",
        "!cp \"/content/nonMotivational.bert_lm.zip\" \"/content/drive/MyDrive\""
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/nonMotivational.bert_lm/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DDnF-Qz414h"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}